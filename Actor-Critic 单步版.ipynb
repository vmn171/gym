{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "#GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "#超参数\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03499601, -0.02108763, -0.02357108, -0.00750943])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1').unwrapped\n",
    "env.action_space.n\n",
    "env.reset()\n",
    "env.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经验重放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Clip = namedtuple('Clip',('state', 'action', 'next_state', 'reward')) #命名元组\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity): #初始化\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args): #添加transition\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Clip(*args)\n",
    "        self.position = (self.position + 1) % self.capacity # %取余数，可以循环\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2774  0.7226\n",
       "[torch.cuda.FloatTensor of size 1x2 (GPU 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ini_net(md):\n",
    "    for m in md.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_normal(m.weight.data)\n",
    "            torch.nn.init.normal(m.bias.data)\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(4,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,2),\n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.MLP(x)\n",
    "        return x\n",
    "    \n",
    "actor_net = ActorNet().cuda()\n",
    "actor_net.apply(ini_net)\n",
    "testx = Variable(torch.randn(1,4)).cuda()\n",
    "actor_net(testx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.8090\n",
       "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CriticNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CriticNet, self).__init__()\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(4,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.MLP(x)\n",
    "        return x\n",
    "       \n",
    "critic_net = CriticNet().cuda()\n",
    "critic_net.apply(ini_net)\n",
    "\n",
    "critic_net2 = deepcopy(critic_net) #延迟网络\n",
    "\n",
    "testx = Variable(torch.randn(1,4)).cuda()\n",
    "critic_net(testx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动作策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, Variable containing:\n",
       " -0.3461\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_action(state):\n",
    "    state = Variable(state)\n",
    "    prob = actor_net(state)\n",
    "    m = Categorical(prob)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    action = action.data.cpu().numpy()[0]\n",
    "    return action, log_prob\n",
    "\n",
    "testx = torch.randn(1,4).cuda()\n",
    "select_action(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memory = ReplayMemory(100000) #10000个重放记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def critic_optimize():\n",
    "    if len(memory) < BATCH_SIZE: #如果记忆长度小于batch_size就弹出\n",
    "        return\n",
    "    \n",
    "    #取出一个批次的片段\n",
    "    clips = memory.sample(BATCH_SIZE) #取一个batch_size长度的transitions\n",
    "    batch = Clip(*zip(*clips)) #打一下包\n",
    "    s2_batch = Variable(torch.cat(batch.next_state),volatile=True)\n",
    "    s_batch = Variable(torch.cat(batch.state))\n",
    "    a_batch = Variable(torch.cat(batch.action))\n",
    "    r_batch = Variable(torch.cat(batch.reward))\n",
    "    \n",
    "    #计算Q(s,a)\n",
    "    Qsa = critic_net(s_batch) \n",
    "\n",
    "    #计算Q(s_,a_) \n",
    "    Qs2a = critic_net2(s2_batch) #取最大的一个，动作\n",
    "    Qs2a = Qs2a.view(-1)\n",
    "    \n",
    "    # 计算y = r + Q(s_,a_)\n",
    "    y = (Qs2a * GAMMA) + r_batch\n",
    "    \n",
    "\n",
    "    # Huber loss\n",
    "    #loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    loss = torch.nn.MSELoss()(Qsa, y)\n",
    "    # 优化model\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    #为了防止值过大，可以裁剪梯度\n",
    "    for param in critic_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer1.step()\n",
    "    return loss\n",
    "\n",
    "def A_error(s, s_, r):\n",
    "    s = Variable(s)\n",
    "    s_ = Variable(s_)    \n",
    "    Qs = critic_net(s)\n",
    "    y = critic_net2(s_).detach() + r\n",
    "    A = y - Qs #实际奖励-估计的奖励\n",
    "    A = A.detach()\n",
    "    return A\n",
    "\n",
    "def actor_loss(log_prob, A):\n",
    "    aloss = -log_prob * A\n",
    "    return aloss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-231.7013\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-235.8995\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-240.8292\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-246.4740\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-252.7981\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-259.7388\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-267.2031\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-275.0610\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-283.1384\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-301.2078\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "num_episodes = 1\n",
    "optimizer1 = optim.Adam(critic_net.parameters(),lr=1e-4)\n",
    "optimizer2 = optim.Adam(actor_net.parameters(),lr=1e-4)\n",
    "\n",
    "def get_state():\n",
    "    state = FloatTensor(env.state).cuda().view(1,-1)\n",
    "    #state = Variable(state)\n",
    "    return state\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # 初始化环境\n",
    "    env.reset()\n",
    "    s = get_state()\n",
    "    step = 0\n",
    "    \n",
    "    closs_sum = 0\n",
    "    aloss_sum = 0\n",
    "    while True: #无限循环\n",
    "        #if i_episode>3500: \n",
    "        #env.render()\n",
    "        \n",
    "        a, log_prob = select_action(s) #根据状态选择一个动作，得到a和log_prob\n",
    "        s_, r, done, _ = env.step(a) #计算该动作的下一个状态，奖励，done   \n",
    "        s_ = get_state()\n",
    "        if done: r -= 10\n",
    "        \n",
    "        #计算该状态的Q(s，a),（输入s,a,s_,r，输出A，critic loss）,然后更新网络\n",
    "        A = A_error(s, s_, r)\n",
    "        \n",
    "        print(A)\n",
    "        \n",
    "        memory.push(s, LongTensor([int(a)]), s_, Tensor([r]))\n",
    "        \n",
    "        #计算该动作的价值，（输入logprob, A，输出actor loss），然后更新网络\n",
    "        aloss = actor_loss(log_prob, A)\n",
    "        optimizer2.zero_grad\n",
    "        aloss.backward()\n",
    "        optimizer2.step()\n",
    "        aloss_sum += aloss.data.cpu().numpy()[0]\n",
    "        \n",
    "        s = s_ \n",
    "        step += 1\n",
    "        \n",
    "        critic_optimize()\n",
    "        \n",
    "        if done:\n",
    "            writer.add_scalar('step', step, i_episode)\n",
    "            writer.add_scalar('aloss', aloss_sum/step, i_episode)\n",
    "            writer.add_scalar('closs', closs_sum/step, i_episode)\n",
    "            #print(i_episode, step)\n",
    "            break\n",
    "    \n",
    "   \n",
    "    if i_episode % 20 == 0:\n",
    "        critic_net2 = deepcopy(critic_net) \n",
    "    \n",
    "print('Complete')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
